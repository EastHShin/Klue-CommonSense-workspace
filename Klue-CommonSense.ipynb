{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95307bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e911640b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paragraphs': [{'qas': [{'question': '다테 기미코가 최초로 은퇴 선언을 한게 언제지',\n",
       "     'answers': [{'answer_start': 260, 'text': '1996년 9월 24일'}],\n",
       "     'id': '9_f2_wiki_2822-1'}],\n",
       "   'context': \"재팬 오픈에서 4회 우승하였으며, 통산 단식 200승 이상을 거두었다. 1994년 생애 최초로 세계 랭킹 10위권에 진입하였다. 1992년에는 WTA로부터 '올해 가장 많은 향상을 보여준 선수상'(Most Improved Player Of The Year)을 수여받았으며, 일본 남자 패션 협회(Japan Men's Fashion Association)는 그녀를 '가장 패셔너블한 선수'(Most Fashionable)로 칭했다. 생애 두 번째 올림픽 참가 직후인 1996년 9월 24일 최초로 은퇴를 선언하였다. 이후 12년만인 2008년 4월에 예상치 못한 복귀 선언을 하고 투어에 되돌아왔다. 2008년 6월 15일 도쿄 아리아케 인터내셔널 여자 오픈에서 복귀 후 첫 우승을 기록했으며, 2009년 9월 27일에는 한국에서 열린 한솔 코리아 오픈 대회에서 우승하면서 복귀 후 첫 WTA 투어급 대회 우승을 기록했다. 한숨 좀 작작 쉬어!\"}],\n",
       " 'title': '다테_기미코'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./ko_wiki_edited.json\", \"rb\") as f:\n",
    "    klue_dict = json.load(f)\n",
    "klue_dict[\"data\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba60415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paragraphs': [{'qas': [{'question': 'ave;new 본거지 어디야',\n",
       "     'answers': [{'answer_start': 22, 'text': '도쿄 치요다구'}],\n",
       "     'id': '9_f2_wiki_3091-1'}],\n",
       "   'context': 'ave;new(아베;뉴, アベニュー)는 도쿄 치요다구에 본 거처를 둔 일본의 음악 제작 그룹이다. ave;new의 프로듀서인 a.k.a.dRESS가 학창시절부터 친구인 네모토 히데미·마츠시타 미유키를 불러 사운드 팀을 시작하자고 제안한 것이 결성의 계기이다. 2003년 7월에 결성된 ave;new는, 주로성인 게임의 주제가나 BGM를 제공하고 있다.주로 파트너 브랜드의 BGM 및 예능 프로덕션도 담당하고 있으며 CD는 그룹명과 같이 ave;new의 라벨로 판매되고 있으나 다른 라벨에 비해 시장에 약간 유통 하기 어렵다.또한 일부의 CD는 d;VIRTU(주식회사 디바트)가 판매하고 있기 때문이다. 음악은테크노계나 트랜스계와 같이 밝은 곡으로부터,재즈나발라드와 같이 조용한 곡까지 폭넓게 제작할 수 있는 것이 특징이다.특히, 신디사이저를 이용한 테크노계의 곡은 높은 평가를 얻고있다. ave;new의 프로듀서인a.k.a.dRESS가 학생시절부터의 친구인 네모토 히데미·마츠시타 미유키를 불러, 사운드 팀을 시작하려고 제안한 것이 결성의 계기다. ave;new라고 하는 브랜드명은 \"avenue\"(길·수단)과 \"new\"(새롭다)이라고 하는 2개의 단어를 조합한 것으로, 항상 창조의 새로운 길과 수단을 모색한다라고 하는 의미를 담고, a.k.a.dRESS가 이름을 붙였다.'}],\n",
       " 'title': 'Ave;new'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_dict[\"data\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807fd025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_klue(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        klue_dict = json.load(f)\n",
    "        \n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for group in tqdm(klue_dict['data']):\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                for answer in qa ['answers']:\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "                    \n",
    "    return contexts, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07a2316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_end_idx(answers, contexts):\n",
    "    for answer, context in zip(answers,contexts):\n",
    "        gold_text = answer['text']\n",
    "        start_idx = answer['answer_start']\n",
    "        end_idx = start_idx + len(gold_text)\n",
    "        \n",
    "        if context[start_idx:end_idx] == gold_text:\n",
    "            answer['answer_end'] = end_idx\n",
    "        elif context[start_idx-1:end_idx-1] == gold_text:\n",
    "            answer['answer_start'] = start_idx - 1\n",
    "            answer['answer_end'] = end_idx-1\n",
    "        elif context[start_idx-2:end_idx-2] == gold_text:\n",
    "            answer['answer_start'] = start_idx-2\n",
    "            answer['answer_end'] = end_idx-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bde5b607",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ed95948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 1446, 22555, 11477, 2116, 3932, 2210, 6530, 27135, 3670, 2367, 2062, 18, 3671, 886, 9775, 16311, 2073, 12982, 2178, 2062, 15513, 3309, 3681, 798, 2073, 5277, 1041, 2678, 11477, 2116, 3670, 2651, 4016, 28674, 18, 3932, 2210, 11945, 2170, 3881, 2460, 6530, 7831, 1060, 10526, 2170, 1513, 2259, 11477, 2165, 2020, 2079, 3979, 6233, 3814, 6530, 24028, 1116, 12468, 17552, 2170, 24902, 3802, 2178, 2116, 23772, 31369, 5844, 2170, 3911, 3569, 2170, 10760, 2205, 2259, 1039, 2073, 1187, 2116, 5740, 2062, 18, 4364, 2079, 11477, 2259, 18673, 2178, 2062, 22, 97, 23, 2210, 16, 3736, 2178, 4000, 4051, 5947, 3670, 2367, 2062, 18, 11477, 2259, 19880, 2062, 2219, 2470, 1174, 18956, 26797, 2145, 1891, 2398, 1322, 2399, 2470, 22152, 2128, 2292, 2097, 26797, 2052, 4026, 4605, 2496, 2259, 11477, 2165, 2020, 27135, 4848, 2259, 1187, 2138, 936, 4538, 18, 11477, 2165, 2020, 2073, 3801, 2210, 6530, 1060, 7831, 7755, 6233, 12314, 4795, 3619, 2210, 2678, 3690, 25848, 2097, 4997, 18787, 2299, 2118, 3979, 2069, 1567, 575, 6233, 4090, 18, 1504, 2170, 3653, 3619, 97, 4041, 2210, 6904, 16311, 6509, 12982, 2178, 2062, 9229, 3681, 11477, 2116, 5947, 20930, 4016, 28674, 18, 3678, 11477, 2165, 2020, 2069, 18306, 26914, 2259, 1174, 18956, 27406, 4815, 2052, 10352, 3671, 886, 9775, 16311, 2073, 18673, 2178, 2062, 15513, 3309, 2116, 2199, 798, 2073, 5277, 1041, 3797, 11477, 2116, 3670, 2651, 575, 2052, 23548, 578, 11945, 2079, 3788, 28674, 18, 11477, 2165, 2020, 2073, 3719, 1891, 814, 2116, 2199, 5409, 15089, 2144, 2138, 18282, 2307, 5844, 2170, 1187, 2138, 1223, 2388, 4016, 28674, 18, 3744, 3740, 2440, 2366, 27923, 2170, 3881, 2460, 9775, 16311, 2079, 11477, 3670, 2210, 2073, 26, 2429, 21608, 97, 3912, 2210, 2052, 2359, 4007, 11477, 2015, 2366, 2073, 4987, 2210, 16, 12068, 2210, 2113, 2259, 3932, 18, 22, 2210, 2052, 2359, 2062, 18, 11945, 2073, 3753, 11477, 2015, 2366, 2079, 4233, 21474, 2052, 10906, 97, 5808, 3569, 2200, 18673, 2145, 4574, 2205, 9253, 1536, 2069, 575, 6233, 11997, 2062, 18, 6621, 5339, 3629, 2145, 4694, 2079, 3682, 2116, 4834, 2259, 3801, 2210, 4400, 3671, 2073, 7663, 7830, 2052, 3732, 712, 3683, 1187, 2259, 12065, 1380, 2069, 575, 6233, 4045, 2811, 4142, 6504, 2170, 2259, 11012, 2052, 1415, 2069, 4016, 28674, 18, 3, 1174, 18956, 26797, 2145, 22152, 2128, 2292, 2097, 26797, 2052, 4026, 3739, 2170, 13402, 2259, 3960, 2073, 35, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은?\"\n",
    "context = \"올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2~3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다.장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20~21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24~25일이었으며 장마기간은 32일, 강수일수는 17.2일이었다.기상청은 올해 장마기간의 평균 강수량이 350~400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다.\"\n",
    "tokenizer(context, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e738a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KlueDataset(Dataset):\n",
    "    def __init__(self, contexts, questions, answers, model_max_position_embedings, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.answers = answers\n",
    "        self.questions = questions\n",
    "        self.contexts = contexts\n",
    "        self.model_max_position_embedings = model_max_position_embedings\n",
    "        print(\"Tokenizing ...\")\n",
    "        self.encodings = self.tokenizer(self.contexts, \n",
    "                                        self.questions,\n",
    "                                        max_length=512,\n",
    "                                        truncation=True,\n",
    "                                        padding=\"max_length\",\n",
    "                                        return_token_type_ids=False)\n",
    "        print(\"Done !!!\")\n",
    "        self.add_token_positions()\n",
    "        \n",
    "    def add_token_positions(self):\n",
    "        start_positions = []\n",
    "        end_positions = []\n",
    "        for i in range(len(self.answers)):\n",
    "            start_positions.append(self.encodings.char_to_token(i, self.answers[i]['answer_start']))\n",
    "            end_positions.append(self.encodings.char_to_token(i, self.answers[i]['answer_end'] - 1))\n",
    "\n",
    "            # positions 값이 None 값이라면, answer가 포함된 context가 잘렸다는 의미\n",
    "            if start_positions[-1] is None:\n",
    "                start_positions[-1] = self.model_max_position_embedings\n",
    "            if end_positions[-1] is None:\n",
    "                end_positions[-1] = self.model_max_position_embedings\n",
    "\n",
    "        self.encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "        \n",
    "    def get_data(self):\n",
    "        return {\"contexts\":self.contexts, 'questions':self.questions, 'answers':self.answers}\n",
    "    \n",
    "    \n",
    "    def get_encodings(self):\n",
    "        return self.encodings\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key:torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8511c3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8897fad395894ab4b0a328d1e81095c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing ...\n",
      "Done !!!\n"
     ]
    }
   ],
   "source": [
    "contexts, questions, answers = read_klue(\"./ko_wiki_edited.json\")\n",
    "add_end_idx(answers,contexts)\n",
    "train_dataset = KlueDataset(contexts, questions, answers, 512, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30b47f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54463657",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 3\n",
    "LEARNING_RATE = 5e-5\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a359e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_runner(model, dataset, batch_size, num_train_epochs, learning_rate):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    train_dataloader = DataLoader(dataset=dataset, batch_size=batch_size)\n",
    "    global_total_step = len(train_dataloader) * num_train_epochs\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0)\n",
    "    print(\"TRAIN START\")\n",
    "    with tqdm(total=global_total_step, unit='step') as t:\n",
    "        total = 0\n",
    "        total_loss = 0\n",
    "        for epoch in range(num_train_epochs):\n",
    "            for batch in train_dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                start_positions = batch['start_positions'].to(device)\n",
    "                end_positions = batch['end_positions'].to(device)\n",
    "                outputs = model(input_ids,\n",
    "                             attention_mask=attention_mask,\n",
    "                             start_positions=start_positions,\n",
    "                             end_positions=end_positions)\n",
    "                loss = outputs.loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                batch_loss = loss.item() * len(input_ids)\n",
    "                total += len(input_ids)\n",
    "                total_loss += batch_loss\n",
    "                global_total_step += 1\n",
    "                t.set_postfix(loss=\"{:.6f}\".format(total_loss / total), batch_loss=\"{:.6f}\".format(batch_loss))\n",
    "                t.update(1)\n",
    "                \n",
    "                del input_ids\n",
    "                del attention_mask\n",
    "                del start_positions\n",
    "                del end_positions\n",
    "                del outputs\n",
    "                del loss\n",
    "    model.save_pretrained(\"./klue_AI_output_model\")\n",
    "    print(\"TRAIN END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee294e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN START\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628386a081ac41d7ba7393da071e2b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16542 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN END\n"
     ]
    }
   ],
   "source": [
    "train_runner(model,train_dataset, BATCH_SIZE, EPOCH, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b89c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dev_klue(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        klue_dict = json.load(f)\n",
    "\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for group in tqdm(klue_dict['data']):\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                temp_answer = []\n",
    "                for answer in qa['answers']:\n",
    "                    temp_answer.append(answer['text'])\n",
    "                if len(temp_answer) != 0: # answers의 길이가 0 == 답변할 수 없는 질문\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(temp_answer)\n",
    "\n",
    "    return contexts, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_contexts, dev_questions, dev_answers = read_dev_klue(\"./ko_wiki_edited_dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4873ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(contexts, questions):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for context, question in zip(contexts, questions):\n",
    "            encodings = tokenizer(context, question, max_length=512, truncation=True,\n",
    "                                     padding=\"max_length\", return_token_type_ids=False)\n",
    "            encodings = {key: torch.tensor([val]) for key, val in encodings.items()}\n",
    "            \n",
    "            input_ids = encodings[\"input_ids\"].to(device)\n",
    "            attention_mask = encodings[\"attention_mask\"].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
    "            token_start_index, token_end_index = start_logits.argmax(dim=-1), end_logits.argmax(dim=-1)\n",
    "            pred_ids = input_ids[0][token_start_index: token_end_index + 1]\n",
    "            pred = tokenizer.decode(pred_ids)\n",
    "            result.append(pred)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea9baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_answers = prediction(dev_contexts, dev_questions)\n",
    "pred_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c38bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_evalutate(prediction_answers, real_answers):\n",
    "    total = len(prediction_answers)\n",
    "    exact_match = 0\n",
    "    for prediction_answer, real_answer in zip(prediction_answers, real_answers):\n",
    "        if prediction_answer in real_answer:\n",
    "            exact_match += 1\n",
    "    \n",
    "    return (exact_match/total) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c835597",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_score = em_evalutate(pred_answers, dev_answers)\n",
    "em_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a5dcf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
